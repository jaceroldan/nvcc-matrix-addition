{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HZIDL8M-zo8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0798a50-bccd-44f5-a5ed-250e60a95c91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n",
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmprnw47xhj\".\n"
          ]
        }
      ],
      "source": [
        "# Install the nvcc4jupyter plugin\n",
        "!pip install nvcc4jupyter\n",
        "\n",
        "# Load the extension into the notebook\n",
        "%load_ext nvcc4jupyter\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "int main() {\n",
        "    int nDevices;\n",
        "    cudaGetDeviceCount(&nDevices);\n",
        "    for (int i = 0; i < nDevices; i++) {\n",
        "        cudaDeviceProp prop;\n",
        "        cudaGetDeviceProperties(&prop, i);\n",
        "        printf(\"Device Number: %d\\n\", i);\n",
        "        printf(\"  Device name: %s\\n\", prop.name);\n",
        "        printf(\"  Memory Clock Rate (KHz): %d\\n\", prop.memoryClockRate);\n",
        "        printf(\"  Memory Bus Width (bits): %d\\n\", prop.memoryBusWidth);\n",
        "        printf(\"  Peak Memory Bandwidth (GB/s): %f\\n\\n\",\n",
        "               2.0*prop.memoryClockRate*(prop.memoryBusWidth/8)/1.0e6);\n",
        "    }\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "yZIkXeUPzxhQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84b79063-99bb-425b-c391-aaba68898f94"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device Number: 0\n",
            "  Device name: Tesla T4\n",
            "  Memory Clock Rate (KHz): 5001000\n",
            "  Memory Bus Width (bits): 256\n",
            "  Peak Memory Bandwidth (GB/s): 320.064000\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#include <vector>\n",
        "\n",
        "inline cudaError_t checkCudaErr(cudaError_t result, char const *const func, const int line) {\n",
        "    if (result != cudaSuccess) {\n",
        "        std::cerr << \"CUDA error = \" << static_cast<int>(result) << \" at \" <<\n",
        "        func << \":\" << line << \" '\" << cudaGetErrorString(result) << \"'\" << std::endl;\n",
        "        exit(1);\n",
        "    }\n",
        "    return result;\n",
        "}\n",
        "#define CUDA_CHECK(val) checkCudaErr((val), __func__, __LINE__)\n",
        "\n",
        "__global__ void matmul_rec_glob(float* A, float* B, float* C, int n, int k, int m) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < n && col < m) {\n",
        "        float sum = 0.0f;\n",
        "        for (int i = 0; i < k; ++i) {\n",
        "            sum += A[row * k + i] * B[i * m + col];\n",
        "        }\n",
        "        C[row * m + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void matmul_rec_shar(float* A, float* B, float* C, int n, int k, int m) {\n",
        "    int bx = blockIdx.x, by = blockIdx.y;\n",
        "    int tx = threadIdx.x, ty = threadIdx.y;\n",
        "    int row = by * blockDim.y + ty;\n",
        "    int col = bx * blockDim.x + tx;\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    __shared__ float sA[32][32]; // Tile size of 32x32\n",
        "    __shared__ float sB[32][32];\n",
        "\n",
        "    for (int t = 0; t < (k + 31) / 32; ++t) {\n",
        "        if (row < n && (t * 32 + tx) < k)\n",
        "            sA[ty][tx] = A[row * k + t * 32 + tx];\n",
        "        else\n",
        "            sA[ty][tx] = 0.0;\n",
        "\n",
        "        if (col < m && (t * 32 + ty) < k)\n",
        "            sB[ty][tx] = B[(t * 32 + ty) * m + col];\n",
        "        else\n",
        "            sB[ty][tx] = 0.0;\n",
        "\n",
        "        __syncthreads();\n",
        "\n",
        "        for (int i = 0; i < 32; ++i) {\n",
        "            sum += sA[ty][i] * sB[i][tx];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (row < n && col < m)\n",
        "        C[row * m + col] = sum;\n",
        "}\n",
        "\n",
        "void initializeMatrix(float* matrix, int rows, int cols) {\n",
        "    for (int i = 0; i < rows * cols; i++) {\n",
        "        matrix[i] = static_cast<float>(rand()) / static_cast<float>(RAND_MAX);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    std::vector<int> sizes = {4, 16, 64, 256, 1024, 4096};\n",
        "    for (int n : sizes) {\n",
        "        int k = n, m = n;\n",
        "        size_t sizeA = n * k * sizeof(float);\n",
        "        size_t sizeB = k * m * sizeof(float);\n",
        "        size_t sizeC = n * m * sizeof(float);\n",
        "\n",
        "        float *h_A, *h_B, *h_C;\n",
        "        float *d_A, *d_B, *d_C;\n",
        "\n",
        "        // Allocate host memory\n",
        "        h_A = (float*)malloc(sizeA);\n",
        "        h_B = (float*)malloc(sizeB);\n",
        "        h_C = (float*)malloc(sizeC);\n",
        "\n",
        "        // Initialize matrices\n",
        "        initializeMatrix(h_A, n, k);\n",
        "        initializeMatrix(h_B, k, m);\n",
        "\n",
        "        // Allocate device memory\n",
        "        CUDA_CHECK(cudaMalloc((void**)&d_A, sizeA));\n",
        "        CUDA_CHECK(cudaMalloc((void**)&d_B, sizeB));\n",
        "        CUDA_CHECK(cudaMalloc((void**)&d_C, sizeC));\n",
        "\n",
        "        // Copy data from host to device\n",
        "        CUDA_CHECK(cudaMemcpy(d_A, h_A, sizeA, cudaMemcpyHostToDevice));\n",
        "        CUDA_CHECK(cudaMemcpy(d_B, h_B, sizeB, cudaMemcpyHostToDevice));\n",
        "\n",
        "        // Setup execution parameters\n",
        "        dim3 threadsPerBlock(32, 32);\n",
        "        dim3 blocksPerGrid((m + threadsPerBlock.x - 1) / threadsPerBlock.x, (n + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
        "\n",
        "        // Timing variables\n",
        "        float milliseconds = 0;\n",
        "        cudaEvent_t start, stop;\n",
        "        CUDA_CHECK(cudaEventCreate(&start));\n",
        "        CUDA_CHECK(cudaEventCreate(&stop));\n",
        "\n",
        "        // Launch kernels multiple times and average the results\n",
        "        int numTrials = 10;\n",
        "        float totalTimeGlob = 0, totalTimeShar = 0;\n",
        "        for (int i = 0; i < numTrials; ++i) {\n",
        "            // Global memory kernel\n",
        "            CUDA_CHECK(cudaEventRecord(start));\n",
        "            matmul_rec_glob<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, n, k, m);\n",
        "            CUDA_CHECK(cudaEventRecord(stop));\n",
        "            CUDA_CHECK(cudaEventSynchronize(stop));\n",
        "            CUDA_CHECK(cudaEventElapsedTime(&milliseconds, start, stop));\n",
        "            totalTimeGlob += milliseconds;\n",
        "\n",
        "            // Shared memory kernel\n",
        "            CUDA_CHECK(cudaEventRecord(start));\n",
        "            matmul_rec_shar<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, n, k, m);\n",
        "            CUDA_CHECK(cudaEventRecord(stop));\n",
        "            CUDA_CHECK(cudaEventSynchronize(stop));\n",
        "            CUDA_CHECK(cudaEventElapsedTime(&milliseconds, start, stop));\n",
        "            totalTimeShar += milliseconds;\n",
        "        }\n",
        "\n",
        "        std::cout << \"Average time for matrix size \" << n << \"x\" << n << \" using global memory: \"\n",
        "                  << totalTimeGlob / numTrials << \" ms\" << std::endl;\n",
        "        std::cout << \"Average time for matrix size \" << n << \"x\" << n << \" using shared memory: \"\n",
        "                  << totalTimeShar / numTrials << \" ms\" << std::endl;\n",
        "\n",
        "        // Free device memory\n",
        "        CUDA_CHECK(cudaFree(d_A));\n",
        "        CUDA_CHECK(cudaFree(d_B));\n",
        "        CUDA_CHECK(cudaFree(d_C));\n",
        "\n",
        "        // Free host memory\n",
        "        free(h_A);\n",
        "        free(h_B);\n",
        "        free(h_C);\n",
        "\n",
        "        CUDA_CHECK(cudaEventDestroy(start));\n",
        "        CUDA_CHECK(cudaEventDestroy(stop));\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wun1d0SL4l28",
        "outputId": "333e56a0-46e1-4c29-dcf8-11f3193ec58b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average time for matrix size 4x4 using global memory: 0.0279488 ms\n",
            "Average time for matrix size 4x4 using shared memory: 0.012512 ms\n",
            "Average time for matrix size 16x16 using global memory: 0.0083488 ms\n",
            "Average time for matrix size 16x16 using shared memory: 0.0113728 ms\n",
            "Average time for matrix size 64x64 using global memory: 0.0221568 ms\n",
            "Average time for matrix size 64x64 using shared memory: 0.0170016 ms\n",
            "Average time for matrix size 256x256 using global memory: 0.133091 ms\n",
            "Average time for matrix size 256x256 using shared memory: 0.109306 ms\n",
            "Average time for matrix size 1024x1024 using global memory: 6.64068 ms\n",
            "Average time for matrix size 1024x1024 using shared memory: 5.32209 ms\n",
            "Average time for matrix size 4096x4096 using global memory: 233.494 ms\n",
            "Average time for matrix size 4096x4096 using shared memory: 157.987 ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mBuvqonN4tKj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}